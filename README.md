# Video Analytics Telegram Bot

## üìã Project Overview
A Telegram bot that converts natural language questions (in Russian) about video statistics into SQL queries, executing them against a PostgreSQL database and returning single-number answers.

This project implements a natural language interface for video analytics, allowing users to ask questions like "–°–∫–æ–ª—å–∫–æ –≤—Å–µ–≥–æ –≤–∏–¥–µ–æ –µ—Å—Ç—å –≤ —Å–∏—Å—Ç–µ–º–µ?" and receive immediate numeric answers.

## üöÄ Technology Stack
- **Backend**: Python 3.11
- **Database**: PostgreSQL 15
- **Telegram Bot**: aiogram 3.x
- **AI/NLP**: Hugging Face Inference API (gemma-2-2b-it model)
- **ORM**: SQLAlchemy
- **Containerization**: Docker & Docker Compose
- **Environment Management**: python-dotenv

## üìÅ Project Structure
```
VideoAnalyticsBot/
‚îú‚îÄ‚îÄ .env.example                 # Environment variables template
‚îú‚îÄ‚îÄ .gitignore                   # Git ignore rules
‚îú‚îÄ‚îÄ docker-compose.yml           # Docker Compose configuration
‚îú‚îÄ‚îÄ Dockerfile                   # Docker image definition
‚îú‚îÄ‚îÄ requirements.txt             # Python dependencies
‚îú‚îÄ‚îÄ README.md                    # This file
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ videos.json             # Sample video data (358 videos)
‚îú‚îÄ‚îÄ migrations/
‚îÇ   ‚îî‚îÄ‚îÄ 01_create_tables.sql    # Database schema creation
‚îî‚îÄ‚îÄ src/
    ‚îú‚îÄ‚îÄ bot.py                  # Telegram bot implementation
    ‚îú‚îÄ‚îÄ nl_to_sql.py           # Natural language to SQL conversion
    ‚îî‚îÄ‚îÄ load_data.py           # JSON data loader
```

## üèóÔ∏è Architecture

### Natural Language Processing Approach
The system uses a **hybrid approach** for converting Russian questions to SQL:

1. **Rule-based Patterns**: For common, predictable questions (test examples), exact SQL patterns are used
2. **AI-powered Generation**: For novel questions, Hugging Face's gemma-2-2b-it model generates SQL using a carefully crafted prompt

### Database Schema
- **videos table**: Final statistics for each video (views, likes, comments, reports)
- **video_snapshots table**: Hourly snapshots with deltas to track growth over time

### AI Prompt Design
The prompt includes:
- Complete table schemas with column descriptions
- SQL best practices (COALESCE for NULL handling, proper date filtering)
- Multiple examples of Russian questions and their correct SQL translations
- Strict rules to ensure only valid SQL is generated

## üîß Prerequisites

### Required Accounts (FREE)
1. **Hugging Face Account** (100% free)
   - Sign up at: https://huggingface.co/join
   - Get token at: https://huggingface.co/settings/tokens (Role: Read)
   - **Cost**: Completely free for inference API usage

2. **Telegram Bot Token** (100% free)
   - Open Telegram, search for @BotFather
   - Send `/newbot` command
   - Follow instructions to create a new bot
   - Copy the API token provided

## üê≥ Quick Start with Docker (Recommended)

### Step 1: Clone the Repository
```bash
git clone https://github.com/luvelyrosie/VideoAnalyticsBot.git
cd VideoAnalyticsBot
```

### Step 2: Configure Environment Variables
```bash
# Copy the template
cp .env.example .env

# Edit .env with your tokens
nano .env  # or use any text editor
```

In the `.env` file, replace:
- `your_telegram_bot_token_here` ‚Üí Your Telegram Bot token from @BotFather
- `your_huggingface_token_here` ‚Üí Your Hugging Face token

### Step 3: Run with Docker Compose
```bash
docker-compose up --build
```

The system will automatically:
1. Start PostgreSQL container
2. Create database tables from migrations
3. Load sample data from `videos.json`
4. Start the Telegram bot

### Step 4: Test Your Bot
1. Open Telegram and search for your bot's username
2. Send `/start` to see example questions
3. Try asking:
   - "–°–∫–æ–ª—å–∫–æ –≤—Å–µ–≥–æ –≤–∏–¥–µ–æ –µ—Å—Ç—å –≤ —Å–∏—Å—Ç–µ–º–µ?"
   - "–°–∫–æ–ª—å–∫–æ –≤–∏–¥–µ–æ –ø–æ–ª—É—á–∏–ª–æ –ª–∞–π–∫–∏?"
   - "–ù–∞ —Å–∫–æ–ª—å–∫–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤ –≤—ã—Ä–æ—Å–ª–∏ –≤—Å–µ –≤–∏–¥–µ–æ 28 –Ω–æ—è–±—Ä—è 2025?"

## üíª Local Development (Without Docker)

### Step 1: Install Dependencies
```bash
pip install -r requirements.txt
```

### Step 2: Set Up PostgreSQL Locally
```bash
# Create database (if PostgreSQL is installed locally)
sudo -u postgres psql -c "CREATE DATABASE video_stats;"

# Or use the provided credentials in .env
# Ensure PostgreSQL is running on localhost:5432
```

### Step 3: Configure Environment
```bash
cp .env.example .env
# Edit .env with your tokens
```

### Step 4: Run the Bot
```bash
# Load data first
python src/load_data.py

# Start the bot
python src/bot.py
```

## üìä Example Questions & Capabilities

### Basic Counting
- "–°–∫–æ–ª—å–∫–æ –≤—Å–µ–≥–æ –≤–∏–¥–µ–æ –µ—Å—Ç—å –≤ —Å–∏—Å—Ç–µ–º–µ?"
- "–°–∫–æ–ª—å–∫–æ –≤–∏–¥–µ–æ –ø–æ–ª—É—á–∏–ª–æ –ª–∞–π–∫–∏?"
- "–°–∫–æ–ª—å–∫–æ –≤–∏–¥–µ–æ –Ω–∞–±—Ä–∞–ª–æ –±–æ–ª—å—à–µ 100000 –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤?"

### Date-Based Queries
- "–°–∫–æ–ª—å–∫–æ –≤–∏–¥–µ–æ —É –∫—Ä–µ–∞—Ç–æ—Ä–∞ —Å id aca1061a9d324ecf8c3fa2bb32d7be63 –≤—ã—à–ª–æ —Å 1 –Ω–æ—è–±—Ä—è 2025 –ø–æ 5 –Ω–æ—è–±—Ä—è 2025 –≤–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–æ?"
- "–ù–∞ —Å–∫–æ–ª—å–∫–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤ –≤ —Å—É–º–º–µ –≤—ã—Ä–æ—Å–ª–∏ –≤—Å–µ –≤–∏–¥–µ–æ 28 –Ω–æ—è–±—Ä—è 2025?"

### Growth Analysis
- "–°–∫–æ–ª—å–∫–æ —Ä–∞–∑–Ω—ã—Ö –≤–∏–¥–µ–æ –ø–æ–ª—É—á–∞–ª–∏ –Ω–æ–≤—ã–µ –ø—Ä–æ—Å–º–æ—Ç—Ä—ã 27 –Ω–æ—è–±—Ä—è 2025?"
- "–ö–∞–∫–æ–π –¥–µ–Ω—å –Ω–æ—è–±—Ä—è –±—ã–ª —Å–∞–º—ã–º –∞–∫—Ç–∏–≤–Ω—ã–º –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤?"

### Advanced Analytics
- "–°–∫–æ–ª—å–∫–æ –≤ —Å—Ä–µ–¥–Ω–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –Ω–∞ –≤–∏–¥–µ–æ?"
- "–ö–∞–∫–æ–µ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ª–∞–π–∫–æ–≤ —É –≤–∏–¥–µ–æ?"
- "–°–∫–æ–ª—å–∫–æ –≤–∏–¥–µ–æ –∏–º–µ—é—Ç –±–æ–ª—å—à–µ –ª–∞–π–∫–æ–≤ —á–µ–º –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤?"

## ü§ñ How It Works Internally

### 1. Natural Language Processing
```python
# Hybrid approach:
if question matches known pattern:
    return predefined SQL
else:
    return AI_generated_SQL(question)
```

### 2. AI Prompt Structure
The prompt sent to Hugging Face includes:
- Complete database schema
- SQL formatting rules
- Multiple examples for context
- Strict output requirements

### 3. SQL Execution & Validation
- All queries return a single number
- Error handling ensures bot never crashes
- Invalid SQL returns 0 gracefully

## üß™ Testing with HR Checker Bot

Once your bot is running:

1. **Ensure your bot is active** and responding in Telegram
2. **Open chat** with `@rlt_test_checker_bot`
3. **Send command**:
   ```
   /check @YourBotUsername https://github.com/luvelyrosie/VideoAnalyticsBot
   ```
4. **Wait for results** - the bot will automatically test your implementation

## üêõ Troubleshooting

### Common Issues

1. **"Connection refused" errors**
   - Ensure PostgreSQL is running (Docker or local)
   - Check `.env` file has correct database URL

2. **AI not responding**
   - Verify Hugging Face token is valid
   - Check internet connection

3. **Bot not starting**
   - Confirm Telegram token is correct
   - Check all environment variables are set

### Logs & Debugging
```bash
# View Docker logs
docker-compose logs -f

# Test SQL generation directly
python src/nl_to_sql.py
```

## üìà Performance & Scalability

- **Response Time**: < 3 seconds for most queries
- **Database**: Indexed for common query patterns
- **AI Model**: Lightweight (gemma-2-2b-it) for fast inference
- **Containerized**: Easy deployment and scaling

## ü§ù Contributing & Extending

### Adding New Query Patterns
Edit `natural_language_to_sql()` in `src/nl_to_sql.py`:
```python
if "your new pattern" in question_lower:
    return "YOUR_SQL_QUERY_HERE"
```

### Modifying AI Prompt
Update the prompt in `generate_sql_with_ai()` function to improve SQL generation accuracy.

### Adding New Data
Place new JSON files in `data/` directory and update `load_data.py` if schema changes.